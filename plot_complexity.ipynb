{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_movie_script(title):\n",
    "    url = f\"https://imsdb.com/scripts/{title.replace(' ', '-')}.html\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return \"Script not found or error loading page.\"\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        script_tag = soup.find('pre')\n",
    "        if not script_tag:\n",
    "            return \"Script text not found in the expected format.\"\n",
    "\n",
    "        for b_tag in script_tag.find_all('b'):\n",
    "            b_tag.decompose()\n",
    "        return script_tag.get_text()\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Example usage\n",
    "script = scrape_movie_script(\"12 Years a Slave\")\n",
    "print(script)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "movie_metadata.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Movie release date', 'Movie box office revenue', 'Movie runtime', 'Movie languages', 'Movie countries', 'Movie genres']\n",
    "movie_metadata['script'] = movie_metadata['Movie name'].apply(scrape_movie_script)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write all the scripts in a file called scripts.txt where between two scripts there is a line break and the name of the movie\n",
    "with open('scripts.txt', 'w') as f:\n",
    "    for index, movie in movie_metadata.iterrows():\n",
    "        f.write(f\"{movie['Movie name']}\\n\")\n",
    "        f.write(f\"{movie['script']}\\n\\n\")\n",
    "        f.write(f\"{'-'*100}\\n\\n\")\n",
    "\n",
    "#now write in a csv file the movie name and the script\n",
    "movie_metadata[['Movie name', 'script']].to_csv('scripts.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    }
   ],
   "source": [
    "final_movie_metadata = pd.read_csv('scripts.csv')\n",
    "final_movie_metadata.head()\n",
    "print(len(final_movie_metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = read_files_and_merge(df_merged, './data/movie_scripts')\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'movie_scripts'\n",
    "if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "# script_files = [file for file in os.listdir(path) if file.startswith('Script_') and file.endswith('.txt')]\n",
    "\n",
    "scripts = {}\n",
    "for filename in os.listdir(folder_path):\n",
    "    # check if the file matches the specified format and is in the provided dataset, construct the path\n",
    "    if filename.startswith('Script_') and filename.endswith('.txt'):\n",
    "        movie_name_from_filename = filename[len('Script_'):-len('.txt')]\n",
    "        file_path = os.path.join(folder_path, filename)          \n",
    "        # read from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_contents = file.read()\n",
    "            scripts[movie_name_from_filename] = file_contents\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_movie_metadata))\n",
    "#if a script is not in the scripts and is in the final_movie_metadata, add it\n",
    "for index, movie in final_movie_metadata.iterrows():\n",
    "    if movie['Movie name'] not in scripts:\n",
    "        scripts[movie['Movie name']] = movie['script']\n",
    "        print(f\"Successfully added script for {movie['Movie name']}\")\n",
    "#make the movie name lowercase\n",
    "scripts = {k.lower(): v for k, v in scripts.items()}\n",
    "\n",
    "print(len(scripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "\n",
    "movie_metadata.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Movie release date', 'Movie box office revenue', 'Movie runtime', 'Movie languages', 'Movie countries', 'Movie genres']\n",
    "\n",
    "movie_metadata['Movie name'] = movie_metadata['Movie name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for movie in list(scripts.keys()):\n",
    "    movie = movie.lower()\n",
    "    if movie not in list(movie_metadata['Movie name']):\n",
    "        scripts.pop(movie)\n",
    "        print(f\"Successfully removed script for {movie}\")\n",
    "print(len(scripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#'all-MiniLM-L6-v2'\n",
    "model='all-MiniLM-L6-v2'\n",
    "script_sentences = sent_tokenize(script)\n",
    "\n",
    "print(len(script_sentences))\n",
    "#compute the sentence embeddings of the script\n",
    "script_sentence_embeddings = model.encode(script_sentences, convert_to_tensor=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_metadata_script_bow_bow = pd.read_csv('movie_metadata_script_bow_bow.csv')\n",
    "movie_metadata_script_bow_bow.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_scripts = movie_metadata_script_bow_bow[['movie_name_script', 'script']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Checking if CUDA (GPU support) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define and load the model, moving it to the appropriate device (GPU or CPU)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Concatenate every 10 sentences\n",
    "movie_scripts['sentences_10'] = movie_scripts['sentences'].apply(lambda x: [' '.join(x[i:i+10]) for i in range(0, len(x), 10)])\n",
    "\n",
    "# Function to process in batches, adjusted for device\n",
    "def process_in_batches(sentences, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        # Convert to tensor and move to the same device as the model\n",
    "        batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "        batch_embeddings = batch_embeddings.to(device)\n",
    "        embeddings.extend(batch_embeddings.cpu())  # Move embeddings back to CPU if needed\n",
    "        print(f\"Processed {i} sentences\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = movie_scripts['sentences_10'].apply(process_in_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = pd.read_csv('movie_embeddings.csv')\n",
    "movie_names=movie_metadata_script_bow_bow['movie_name_script']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings.shape\n",
    "\n",
    "\n",
    "#convert movie_embeddings to a numpy array\n",
    "movie_embeddings = movie_embeddings.to_numpy()\n",
    "movie_embeddings[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movie_complexity_scores = []\n",
    "\n",
    "# Iterate over each movie\n",
    "for i,movie in enumerate(movie_embeddings):\n",
    "    movie_complexity_score = 0\n",
    "    print(f\"Processing movie {movie_names[i]}\")\n",
    "    \n",
    "    # Iterate over each sentence embedding and compute cosine similarity with the next three sentences\n",
    "    for i in range(len(movie) - 3):\n",
    "        # Reshape the embeddings to 2D arrays for cosine similarity calculation\n",
    "        emb_current = movie[i].reshape(1, -1)\n",
    "        emb_next1 = movie[i+1].reshape(1, -1)\n",
    "        emb_next2 = movie[i+2].reshape(1, -1)\n",
    "        emb_next3 = movie[i+3].reshape(1, -1)\n",
    "\n",
    "        # Compute the cosine similarity between the current sentence and the next three sentences\n",
    "        similarity1 = cosine_similarity(emb_current, emb_next1)[0][0]\n",
    "        similarity2 = cosine_similarity(emb_current, emb_next2)[0][0]\n",
    "        similarity3 = cosine_similarity(emb_current, emb_next3)[0][0]\n",
    "\n",
    "        # Compute the average similarity\n",
    "        average_similarity = np.mean([similarity1, similarity2, similarity3])\n",
    "        # Add the average similarity to the movie complexity score\n",
    "        movie_complexity_score += average_similarity\n",
    "\n",
    "    # Add the movie complexity score to the list   \n",
    "    movie_complexity_scores.append(movie_complexity_score/len(movie))\n",
    "\n",
    "    \n",
    "# movie_complexity_scores contains the complexity scores for each movie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for each year, compute the average complexity score of the movies and plot it\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "complexity_scores = pd.DataFrame({'movie_name': movie_names, 'complexity_score': movie_complexity_scores})\n",
    "movie_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "movie_metadata.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Movie release date', 'Movie box office revenue', 'Movie runtime', 'Movie languages', 'Movie countries', 'Movie genres']\n",
    "#for each year, compute the average complexity score of the movies and plot it\n",
    "complexity_scores['Movie name'] = complexity_scores['movie_name'].str.lower()\n",
    "movie_metadata['Movie name'] = movie_metadata['Movie name'].str.lower()\n",
    "complexity_scores = complexity_scores.merge(movie_metadata[['Movie name', 'Movie release date']], on='Movie name')\n",
    "complexity_scores['Movie release date'] = pd.to_datetime(complexity_scores['Movie release date'])\n",
    "complexity_scores['year'] = complexity_scores['Movie release date'].dt.year\n",
    "complexity_scores = complexity_scores.groupby('year').mean().reset_index()\n",
    "complexity_scores.head()\n",
    "#plot the complexity score for each year\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(data=complexity_scores, x='year', y='complexity_score')\n",
    "plt.title(\"Average complexity score of movies per year\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "complexity_scores['year'] = complexity_scores['year'].apply(lambda x: x - x%3)\n",
    "complexity_scores = complexity_scores.groupby('year').mean().reset_index()\n",
    "complexity_scores.head()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(data=complexity_scores, x='year', y='complexity_score')\n",
    "plt.title(\"Average complexity score of movies per year\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5  # Set the window size for moving average\n",
    "complexity_scores['moving_avg_complexity'] = complexity_scores['complexity_score'].rolling(window=window_size).mean()\n",
    "\n",
    "\n",
    "# Group by year and calculate mean and standard deviation for confidence intervals\n",
    "yearly_stats = complexity_scores.groupby('year').agg({'moving_avg_complexity': ['mean', 'std']}).reset_index()\n",
    "yearly_stats.columns = ['year', 'avg_complexity', 'std_complexity']\n",
    "\n",
    "# Plotting with confidence intervals\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(data=yearly_stats, x='year', y='avg_complexity', err_style=\"band\", ci='std')\n",
    "plt.title(\"Average complexity score of movies per year with Moving Average and Confidence Intervals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for complexity scores\n",
    "complexity_scores = pd.DataFrame({'movie_name': movie_names, 'complexity_score': movie_complexity_scores})\n",
    "\n",
    "# Your existing movie_metadata code...\n",
    "movie_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "movie_metadata.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Movie release date', 'Movie box office revenue', 'Movie runtime', 'Movie languages', 'Movie countries', 'Movie genres']\n",
    "\n",
    "complexity_scores['Movie name'] = complexity_scores['movie_name'].str.lower()\n",
    "movie_metadata['Movie name'] = movie_metadata['Movie name'].str.lower()\n",
    "complexity_scores = complexity_scores.merge(movie_metadata[['Movie name', 'Movie release date']], on='Movie name')\n",
    "complexity_scores['Movie release date'] = pd.to_datetime(complexity_scores['Movie release date'])\n",
    "complexity_scores['year'] = complexity_scores['Movie release date'].dt.year\n",
    "\n",
    "# Calculate the moving average for complexity scores\n",
    "window_size = 5  # Set the window size for moving average\n",
    "complexity_scores['moving_avg_complexity'] = complexity_scores['complexity_score'].rolling(window=window_size).mean()\n",
    "\n",
    "# Group by year and calculate mean and standard deviation for confidence intervals\n",
    "yearly_stats = complexity_scores.groupby('year').agg({'moving_avg_complexity': ['mean', 'std']}).reset_index()\n",
    "yearly_stats.columns = ['year', 'avg_complexity', 'std_complexity']\n",
    "\n",
    "# Plotting with confidence intervals\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.lineplot(data=yearly_stats, x='year', y='avg_complexity', err_style=\"band\", ci='std')\n",
    "plt.title(\"Average complexity score of movies per year with Moving Average and Confidence Intervals\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4fcbce3-506f-4ece-a09a-ddc8e95c9fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import json\n",
    "import tarfile\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "from data_preprocessing import * \n",
    "from imdb_ratings_scraper import *\n",
    "import load_functions as lf\n",
    "\n",
    "import spacy, nltk, gensim, sklearn\n",
    "import pyLDAvis.gensim_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aef02a4-f325-4d66-819c-dfc6edd55eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = './data/MovieSummaries/'\n",
    "(movie_metadata, character_metadata, name_clusters, plot_summaries, test_data) = \\\n",
    "    lf.load_movie_summaries(data_folder)\n",
    "plot_summaries = pd.merge(plot_summaries, movie_metadata[['wiki_movie_id','movie_name','release_date']], on=\"wiki_movie_id\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5781936-e618-4bc1-8fc0-a5ba659be21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan's in movie_name 99\n",
      "Number of nan's in movie_name 2717\n"
     ]
    }
   ],
   "source": [
    "#number of nan in movie_name\n",
    "print(\"Number of nan's in movie_name {}\".format(plot_summaries.movie_name.isna().sum()))\n",
    "#number of nan in release_date\n",
    "print(\"Number of nan's in movie_name {}\".format(plot_summaries.release_date.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b41f039-284c-4799-abd5-99fa50964a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42303\n"
     ]
    }
   ],
   "source": [
    "#amount of plots\n",
    "print(len(plot_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5be6c76-2d11-48e2-97d6-b295b984759c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = plot_summaries[\"plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c197104-6757-4248-aa40-16ea06506c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots_list = list(plots)\n",
    "plots_list_test = plots_list[:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ade741-6ecb-4e78-bfbd-88e97dd1b8ee",
   "metadata": {},
   "source": [
    "At the moment, don't filter out short plots yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f669e89c-5192-4aad-97a6-d3382b5e8993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35339dab-a437-4a8b-b77a-5e58e8b2ab7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOPWORDS = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "processed_plots = list()\n",
    "for doc in nlp.pipe(plots_list_test, n_process=5, batch_size=10):\n",
    "\n",
    "    # Process document using Spacy NLP pipeline.\n",
    "    ents = doc.ents  # Named entities\n",
    "\n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    # Remove common words from a stopword list and keep only words of length 3 or more.\n",
    "    doc = [token for token in doc if token not in STOPWORDS and len(token) > 2]\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    doc.extend([str(entity) for entity in ents if len(entity) > 1])\n",
    "\n",
    "    processed_plots.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e4cc30c-95f7-487b-8a79-aee905a45c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add bigrams too\n",
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "# Add bigrams to docs (only ones that appear 25 times or more).\n",
    "bigram = Phrases(processed_plots, min_count=25)\n",
    "\n",
    "for idx in range(len(processed_plots)):\n",
    "    for token in bigram[processed_plots[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            processed_plots[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf0ca572-c9e6-4887-aad8-b68d470847f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents, and filter out frequent and rare words.\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(processed_plots)\n",
    "\n",
    "# Remove rare and common tokens.\n",
    "# Filter out words that occur too frequently or too rarely.\n",
    "max_freq = 0.5\n",
    "min_wordcount = 5\n",
    "dictionary.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_plots]\n",
    "#MmCorpus.serialize(\"models/corpus.mm\", corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ea7d4e4-dc2d-41d8-b0df-833436f6bc17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models\n",
    "seed = 42\n",
    "from gensim.models import LdaMulticore\n",
    "params = {'passes': 30, 'random_state': seed}\n",
    "base_models = dict()\n",
    "model = LdaMulticore(corpus=corpus, num_topics=10, id2word=dictionary, workers=6,\n",
    "                passes=params['passes'], random_state=params['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fb246d5-0824-4b9a-9dc7-7bd77f52a372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"film\" + 0.007*\"school\" + 0.006*\"play\" + 0.005*\"friend\" + 0.005*\"tell\" + 0.005*\"leave\" + 0.005*\"year\" + 0.004*\"New\"'),\n",
       " (1,\n",
       "  '0.013*\"kill\" + 0.010*\"man\" + 0.009*\"find\" + 0.007*\"tell\" + 0.007*\"leave\" + 0.006*\"car\" + 0.006*\"try\" + 0.005*\"police\"'),\n",
       " (2,\n",
       "  '0.008*\"find\" + 0.006*\"kill\" + 0.005*\"try\" + 0.004*\"leave\" + 0.004*\"attack\" + 0.004*\"Nick\" + 0.004*\"escape\" + 0.004*\"man\"'),\n",
       " (3,\n",
       "  '0.011*\"love\" + 0.010*\"father\" + 0.009*\"life\" + 0.008*\"family\" + 0.008*\"find\" + 0.007*\"man\" + 0.007*\"son\" + 0.006*\"marry\"'),\n",
       " (4,\n",
       "  '0.010*\"kill\" + 0.010*\"house\" + 0.010*\"find\" + 0.008*\"Sam\" + 0.007*\"police\" + 0.006*\"tell\" + 0.006*\"man\" + 0.006*\"murder\"'),\n",
       " (5,\n",
       "  '0.008*\"find\" + 0.007*\"Ben\" + 0.006*\"Jenny\" + 0.006*\"car\" + 0.005*\"time\" + 0.005*\"Max\" + 0.004*\"try\" + 0.004*\"leave\"'),\n",
       " (6,\n",
       "  '0.007*\"kill\" + 0.005*\"find\" + 0.005*\"ship\" + 0.005*\"leave\" + 0.005*\"Jack\" + 0.005*\"attack\" + 0.004*\"destroy\" + 0.004*\"Jason\"'),\n",
       " (7,\n",
       "  '0.010*\"film\" + 0.006*\"find\" + 0.006*\"tell\" + 0.006*\"leave\" + 0.006*\"girl\" + 0.005*\"ask\" + 0.005*\"house\" + 0.005*\"come\"'),\n",
       " (8,\n",
       "  '0.013*\"Tom\" + 0.010*\"Peter\" + 0.009*\"tell\" + 0.008*\"find\" + 0.006*\"leave\" + 0.006*\"try\" + 0.005*\"Jake\" + 0.005*\"Jerry\"'),\n",
       " (9,\n",
       "  '0.007*\"George\" + 0.007*\"Frank\" + 0.004*\"Roy\" + 0.004*\"play\" + 0.004*\"War\" + 0.004*\"try\" + 0.004*\"Chris\" + 0.004*\"Kid\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics(num_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92fd86ca-8ff6-49b4-8e1e-fab8404f7782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.014542841),\n",
       " (1, 0.1894034),\n",
       " (3, 0.11207339),\n",
       " (5, 0.5149776),\n",
       " (6, 0.16745244)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[corpus[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf66745-b6fa-4334-a3ae-ab3098257434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 2), (12, 1), (13, 1), (14, 1), (15, 3), (16, 7), (17, 5), (18, 2), (19, 8), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 2), (57, 1), (58, 3), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 2), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 2), (78, 1), (79, 1), (80, 1), (81, 3), (82, 1), (83, 2), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 2), (94, 1), (95, 3), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 2), (104, 2), (105, 2), (106, 2), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 2), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 2), (123, 1), (124, 6), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 3), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 2), (147, 1), (148, 1), (149, 1), (150, 1), (151, 2), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 2), (158, 1), (159, 1), (160, 1), (161, 1), (162, 2), (163, 1), (164, 1), (165, 3), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 2), (176, 1), (177, 1), (178, 1), (179, 2), (180, 3), (181, 2), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 3), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 2), (196, 1), (197, 2), (198, 1), (199, 1), (200, 2), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 2), (213, 1), (214, 1), (215, 2), (216, 1), (217, 2), (218, 1), (219, 1), (220, 2), (221, 1), (222, 2), (223, 1), (224, 1), (225, 1), (226, 2), (227, 7), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 2), (234, 1), (235, 1), (236, 3), (237, 1), (238, 1), (239, 1), (240, 1), (241, 2), (242, 1), (243, 2), (244, 1), (245, 1)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6311686-a64f-40c9-9133-c5754dfa8680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

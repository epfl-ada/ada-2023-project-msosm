{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/oriol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/oriol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/oriol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "\n",
    "# from main import plot_summaries, \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v1, v2):\n",
    "    print(set(v1) & set(v2))\n",
    "    return sum(v1[key] * v2[key] for key in set(v1) & set(v2))\n",
    "\n",
    "def magnitude(vector):\n",
    "    return sqrt(sum(value**2 for value in vector.values()))\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2) / (magnitude(v1) * magnitude(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_name(word):\n",
    "    # Use WordNet to check if the word is a proper noun (Assuming person names are proper nouns)\n",
    "    synsets = wordnet.synsets(word)\n",
    "\n",
    "    for synset in synsets:\n",
    "        if synset.pos() == 'n':\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_verb(word):\n",
    "    # Use WordNet to check if the word is a verb\n",
    "    synsets = wordnet.synsets(word)\n",
    "    for synset in synsets:\n",
    "        if synset.pos() == 'v':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_words(word):\n",
    "    # Sometimes people's name can also be verbs, therefore we should remove them first\n",
    "    # For instance, to carol: to sing especially in a joyful manner\n",
    "    # Also it may induce similarities which are not there. There are both Harry's in Harry Potter and Mamma Mia without having anything in common\n",
    "    # TODO: function not working properly\n",
    "\n",
    "    return is_verb(word) # or is_name(word)\n",
    "\n",
    "def get_infinitive_form(verb):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    infinitive_form = lemmatizer.lemmatize(verb, pos='v')\n",
    "    return infinitive_form\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text and while remove all punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Lowercase everything and filter out stopwords\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Sometimes people's name can also be verbs, therefore we should remove them first\n",
    "    # For instance, to carol: to sing especially in a joyful manner\n",
    "    # Also it may induce similarities which are not there. There are both Harry's in Harry Potter and Mamma Mia without having anything in common\n",
    "    # TODO: function not working properly\n",
    "    # words = list(filter(lambda word: not is_name(word), words))\n",
    "    \n",
    "    # Separate verbs and others to obtain the infinitive form and be able to generalizes\n",
    "    verbs = list(filter(is_verb, words))\n",
    "    others = list(filter(lambda word: not is_verb(word), words))\n",
    "\n",
    "    # Transform verbs into their infinitive form\n",
    "    verbs = [get_infinitive_form(verb) for verb in verbs]\n",
    "\n",
    "    # Count words appearance and keep the 100 most common\n",
    "    words = Counter(verbs + others).most_common(100)\n",
    "    print(words)\n",
    "\n",
    "    return dict(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('katniss', 24), ('peeta', 16), ('rue', 11), ('district', 10), ('kill', 6), ('game', 5), ('12', 5), ('crane', 4), ('tributes', 4), ('haymitch', 4), ('cato', 4), ('provide', 3), ('warn', 3), ('medicine', 3), ('run', 3), ('find', 3), ('shoot', 3), ('change', 3), ('cleave', 3), ('tribute', 3), ('nightlock', 3), ('hunger', 2), ('take', 2), ('give', 2), ('career', 2), ('win', 2), ('love', 2), ('gain', 2), ('sponsor', 2), ('gift', 2), ('televise', 2), ('supply', 2), ('call', 2), ('tree', 2), ('draw', 2), ('gather', 2), ('hear', 2), ('spear', 2), ('die', 2), ('riot', 2), ('snow', 2), ('make', 2), ('rule', 2), ('proclaim', 2), ('feast', 2), ('thresh', 2), ('time', 2), ('berry', 2), ('capitol', 2), ('past', 2), ('must', 2), ('boy', 2), ('girl', 2), ('death', 2), ('arena', 2), ('survivor', 2), ('first', 2), ('however', 2), ('half', 2), ('away', 2), ('cornucopia', 2), ('alliance', 2), ('poisonous', 2), ('tracker', 2), ('jacker', 2), ('around', 2), ('instead', 2), ('arrow', 2), ('11', 2), ('president', 2), ('creatures', 2), ('consist', 1), ('age', 1), ('select', 1), ('fight', 1), ('sole', 1), ('reward', 1), ('reap', 1), ('choose', 1), ('volunteer', 1), ('place', 1), ('bread', 1), ('starve', 1), ('accompany', 1), ('drink', 1), ('mentor', 1), ('train', 1), ('interview', 1), ('reveal', 1), ('outrage', 1), ('believe', 1), ('support', 1), ('tool', 1), ('discover', 1), ('mean', 1), ('say', 1), ('begin', 1), ('survive', 1), ('ignore', 1), ('tempt', 1)]\n",
      "[('sean', 56), ('takashi', 28), ('han', 27), ('race', 15), ('neela', 12), ('drive', 7), ('try', 7), ('drift', 7), ('twinkie', 7), ('school', 6), ('time', 6), ('one', 6), ('clay', 6), ('tokyo', 6), ('dad', 6), ('dk', 6), ('kamata', 6), ('leave', 5), ('help', 5), ('road', 5), ('car', 5), ('morimoto', 5), ('get', 4), ('move', 4), ('arrive', 4), ('go', 4), ('meet', 4), ('know', 4), ('take', 4), ('garage', 4), ('pull', 4), ('show', 4), ('crew', 4), ('silvia', 4), ('next', 4), ('challenge', 3), ('damage', 3), ('total', 3), ('father', 3), ('stay', 3), ('tell', 3), ('use', 3), ('lead', 3), ('ram', 3), ('front', 3), ('find', 3), ('make', 3), ('line', 3), ('end', 3), ('local', 3), ('street', 3), ('away', 3), ('business', 3), ('around', 3), ('also', 3), ('nissan', 3), ('day', 3), ('mountain', 3), ('challenger', 3), ('dominic', 3), ('police', 2), ('avoid', 2), ('mother', 2), ('see', 2), ('talk', 2), ('cause', 2), ('rear', 2), ('catch', 2), ('house', 2), ('pass', 2), ('process', 2), ('bone', 2), ('crash', 2), ('flip', 2), ('send', 2), ('live', 2), ('warn', 2), ('back', 2), ('unite', 2), ('state', 2), ('lot', 2), ('confront', 2), ('agree', 2), ('work', 2), ('become', 2), ('give', 2), ('learn', 2), ('gain', 2), ('right', 2), ('hand', 2), ('win', 2), ('inform', 2), ('gun', 2), ('shoot', 2), ('close', 2), ('continue', 2), ('traffic', 2), ('kill', 2), ('manage', 2), ('return', 2)]\n",
      "[('harry', 24), ('voldemort', 10), ('wand', 10), ('ron', 9), ('hermione', 9), ('sword', 7), ('locket', 7), ('see', 5), ('kill', 5), ('death', 5), ('dumbledore', 5), ('trio', 5), ('use', 4), ('take', 4), ('learn', 4), ('escape', 4), ('scrimgeour', 4), ('ministry', 4), ('eaters', 4), ('elder', 4), ('arrive', 3), ('burrow', 3), ('claim', 3), ('lie', 3), ('reveal', 3), ('black', 3), ('visit', 3), ('break', 3), ('malfoy', 3), ('weasley', 3), ('vision', 3), ('ollivander', 3), ('gryffindor', 3), ('dobby', 3), ('wilderness', 3), ('bellatrix', 3), ('minister', 2), ('even', 2), ('lord', 2), ('drive', 2), ('order', 2), ('home', 2), ('torment', 2), ('place', 2), ('discover', 2), ('house', 2), ('steal', 2), ('destroy', 2), ('wear', 2), ('fall', 2), ('grave', 2), ('ice', 2), ('also', 2), ('manor', 2), ('privet', 2), ('meanwhile', 2), ('polyjuice', 2), ('potion', 2), ('maker', 2), ('first', 2), ('godric', 2), ('next', 2), ('12', 2), ('grimmauld', 2), ('horcrux', 2), ('kreacher', 2), ('fletcher', 2), ('accidentally', 2), ('apparates', 2), ('bagshot', 2), ('grindelwald', 2), ('pond', 2), ('lovegood', 2), ('symbol', 2), ('address', 1), ('state', 1), ('remain', 1), ('gain', 1), ('inform', 1), ('commandeer', 1), ('twin', 1), ('gather', 1), ('escort', 1), ('create', 1), ('decoy', 1), ('flight', 1), ('ambush', 1), ('eye', 1), ('injure', 1), ('distribute', 1), ('receive', 1), ('copy', 1), ('bard', 1), ('snitch', 1), ('catch', 1), ('match', 1), ('bequeath', 1), ('explain', 1), ('pass', 1), ('case', 1)]\n",
      "[('sophie', 28), ('donna', 26), ('wed', 9), ('rosie', 9), ('bill', 8), ('men', 8), ('sam', 8), ('tanya', 8), ('three', 7), ('reveal', 6), ('mother', 6), ('father', 6), ('tell', 6), ('sky', 6), ('gimme', 6), ('harry', 5), ('find', 4), ('get', 4), ('marry', 4), ('dance', 4), ('away', 4), ('know', 3), ('sing', 3), ('interrupt', 3), ('party', 3), ('ask', 3), ('give', 3), ('want', 3), ('kalokairi', 3), ('villa', 3), ('secret', 3), ('arrive', 2), ('learn', 2), ('invite', 2), ('believe', 2), ('explain', 2), ('beg', 2), ('see', 2), ('speak', 2), ('leave', 2), ('confide', 2), ('keep', 2), ('sail', 2), ('lose', 2), ('talk', 2), ('confront', 2), ('say', 2), ('confess', 2), ('help', 2), ('walk', 2), ('play', 2), ('present', 2), ('love', 2), ('credit', 2), ('old', 2), ('sheridan', 2), ('invitations', 2), ('friends', 2), ('former', 2), ('daughter', 2), ('fountain', 2), ('aphrodite', 2), ('could', 2), ('fianc√©e', 2), ('sofia', 2), ('must', 2), ('young', 2), ('call', 1), ('post', 1), ('dream', 1), ('set', 1), ('best', 1), ('base', 1), ('spend', 1), ('time', 1), ('reunite', 1), ('wisecrack', 1), ('author', 1), ('desire', 1), ('show', 1), ('rumour', 1), ('build', 1), ('finance', 1), ('smuggle', 1), ('room', 1), ('send', 1), ('hide', 1), ('surprise', 1), ('overhear', 1), ('work', 1), ('hum', 1), ('swear', 1), ('spy', 1), ('dumbfound', 1), ('face', 1), ('forget', 1), ('rally', 1), ('spirit', 1), ('staff', 1), ('yacht', 1)]\n",
      "{'away', 'find', 'time', 'win', 'make', 'kill', 'around', 'gain', 'take', 'warn', 'give', 'shoot'}\n",
      "{'reveal', 'gather', 'discover', 'first', 'place', 'kill', '12', 'gain', 'take', 'death'}\n",
      "{'away', 'must', 'find', 'reveal', 'call', 'time', 'say', 'love', 'give', 'believe'}\n",
      "{'arrive', 'reveal', 'explain', 'learn', 'harry', 'see'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.\n",
    "Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary.\n",
    "'''\n",
    "\n",
    "data_folder = './data/MovieSummaries/'\n",
    "plot_summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep='\\t', header=None)\n",
    "plot_summaries.columns = ['wiki_movie_id', 'plot']\n",
    "plot_summaries.set_index('wiki_movie_id')\n",
    "\n",
    "plot_summaries['count_words'] = plot_summaries.apply(lambda x: len(str(x['plot']).split()), axis=1)\n",
    "\n",
    "# Drop plots with less than 200 words\n",
    "plot_summaries.drop(plot_summaries[plot_summaries['count_words'] < 200].index, inplace= True)\n",
    "\n",
    "# Preprocess the synopses\n",
    "# The Hunger Games\n",
    "preprocessed_synopsis1 = preprocess_text(plot_summaries.query(\"wiki_movie_id == 31186339\").iloc[0]['plot'])\n",
    "\n",
    "# Fast and Furious: Tokyo Drift\n",
    "preprocessed_synopsis2 = preprocess_text(plot_summaries.query(\"wiki_movie_id == 2913859\").iloc[0]['plot'])\n",
    "\n",
    "# Harry Potter: Deathly Hallows Part I\n",
    "preprocessed_synopsis3 = preprocess_text(plot_summaries.query(\"wiki_movie_id == 9834441\").iloc[0]['plot'])\n",
    "\n",
    "# Mamma mia\n",
    "preprocessed_synopsis4 = preprocess_text(plot_summaries.query(\"wiki_movie_id == 8425661\").iloc[0]['plot'])\n",
    "\n",
    "\n",
    "similarity_1 = cosine_similarity(preprocessed_synopsis1, preprocessed_synopsis2)\n",
    "similarity_2 = cosine_similarity(preprocessed_synopsis1, preprocessed_synopsis3)\n",
    "similarity_3 = cosine_similarity(preprocessed_synopsis1, preprocessed_synopsis4)\n",
    "similarity_4 = cosine_similarity(preprocessed_synopsis3, preprocessed_synopsis4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity interpretation and validation\n",
    "If cosine similarity is equal to 1 means both plots are identical. On the other side, if cosine similarity is equal to 0 means the plots have nothing in common.\n",
    "\n",
    "Overviewing the below similarities, it makes sense that \"The Hunger Games\" is more similar to a film such as \"Harry Potter: Deathly Hallows Part 1\" for more common actions such as \"kill\", \"reveal\" and \"take\" than to Fast&Furious and Mamma Mia. This actions may appear also in the latter movies but with less relevance.\n",
    "\n",
    "And unusual phenomena is observed when comparing Harry Potter to Mamma Mia. Using the user's experience, one can argue these films are not very much alike. Investigating the issue further, we discover that this high value on similarity is due to one of the main protagonist for both films are called Harry.\n",
    "\n",
    "Filtering people's name might be necessary to refine the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity The Hunger Games - F&F:Tokyo Drift: 0.026975877067461216\n",
      "Cosine Similarity The Hunger Games - HP: Deathly Hallows P1: 0.04661951635374365\n",
      "Cosine Similarity The Hunger Games - Mamma mia: 0.02453380541675334\n",
      "Cosine Similarity HP: Death Hollows P1 - Mamma mia: 0.08147550915738545\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cosine Similarity The Hunger Games - F&F:Tokyo Drift: {similarity_1}\")\n",
    "print(f\"Cosine Similarity The Hunger Games - HP: Deathly Hallows P1: {similarity_2}\")\n",
    "print(f\"Cosine Similarity The Hunger Games - Mamma mia: {similarity_3}\")\n",
    "print(f\"Cosine Similarity HP: Death Hollows P1 - Mamma mia: {similarity_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity computation by year\n",
    "We are interested on how much similar are movies released on the same year are alike"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
